<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Streaming Automatic Speech Recognition</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            margin: 0;
        }

        .app-wrapper {
            max-width: 1400px;
            margin: 0 auto;
            height: calc(100vh - 40px);
            display: flex;
            flex-direction: column;
        }

        .header {
            background: white;
            border-radius: 12px 12px 0 0;
            padding: 20px 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .header-top {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }

        .session-info {
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 12px;
            color: #6b7280;
        }

        .session-id {
            font-family: monospace;
            background: #f3f4f6;
            padding: 4px 8px;
            border-radius: 4px;
        }

        #shareBtn {
            background: #667eea;
            color: white;
            padding: 6px 12px;
            font-size: 12px;
        }

        #shareBtn:hover:not(:disabled) {
            background: #5568d3;
        }

        .container {
            display: flex;
            gap: 20px;
            flex: 1;
            background: white;
            border-radius: 0 0 12px 12px;
            overflow: hidden;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        .left-pane {
            flex: 1.5;
            padding: 30px;
            overflow-y: auto;
            border-right: 2px solid #e5e7eb;
        }

        .right-pane {
            flex: 1;
            padding: 30px;
            background: #f9fafb;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .controls {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        button {
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        #startBtn {
            background: #10b981;
            color: white;
        }

        #startBtn:hover:not(:disabled) {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4);
        }

        #stopBtn {
            background: #ef4444;
            color: white;
        }

        #stopBtn:hover:not(:disabled) {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(239, 68, 68, 0.4);
        }

        .status {
            padding: 12px;
            border-radius: 6px;
            margin-bottom: 20px;
            font-size: 14px;
            font-weight: 500;
        }

        .status.disconnected {
            background: #fee;
            color: #c00;
            border: 1px solid #fcc;
        }

        .status.connecting {
            background: #fef3c7;
            color: #92400e;
            border: 1px solid #fde68a;
        }

        .status.connected {
            background: #d1fae5;
            color: #065f46;
            border: 1px solid #6ee7b7;
        }

        .status.recording {
            background: #dbeafe;
            color: #1e40af;
            border: 1px solid #93c5fd;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.8; }
        }

        .transcript-box {
            background: #f9fafb;
            border: 2px solid #e5e7eb;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .transcript-entry {
            margin-bottom: 16px;
            padding: 12px;
            background: white;
            border-radius: 6px;
            border-left: 4px solid #667eea;
        }

        .transcript-entry.partial {
            border-left-color: #94a3b8;
            opacity: 0.7;
            font-style: italic;
        }

        .transcript-entry.final {
            border-left-color: #10b981;
        }

        .transcript-label {
            font-size: 11px;
            text-transform: uppercase;
            font-weight: 700;
            color: #666;
            margin-bottom: 6px;
            letter-spacing: 0.5px;
        }

        .transcript-text {
            color: #1f2937;
            line-height: 1.6;
            font-size: 15px;
        }

        .settings {
            background: #f3f4f6;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
        }

        .setting-group {
            margin-bottom: 15px;
        }

        .setting-group:last-child {
            margin-bottom: 0;
        }

        label {
            display: block;
            margin-bottom: 6px;
            font-weight: 600;
            font-size: 13px;
            color: #374151;
        }

        input, select {
            width: 100%;
            padding: 10px;
            border: 2px solid #d1d5db;
            border-radius: 6px;
            font-size: 14px;
            transition: border-color 0.2s;
        }

        input:focus, select:focus {
            outline: none;
            border-color: #667eea;
        }

        .footer {
            text-align: center;
            color: #9ca3af;
            font-size: 12px;
            margin-top: 20px;
        }

        .indicator {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 8px;
        }

        .indicator.green {
            background: #10b981;
            box-shadow: 0 0 8px #10b981;
        }

        .indicator.red {
            background: #ef4444;
        }

        .indicator.yellow {
            background: #f59e0b;
        }

        /* AI Panel Styles */
        .panel-title {
            font-size: 18px;
            font-weight: 700;
            color: #1f2937;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .action-buttons {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .action-btn {
            padding: 8px 16px;
            background: white;
            color: #374151;
            border: 2px solid #d1d5db;
            font-size: 13px;
            flex: 1;
            min-width: 120px;
        }

        .action-btn:hover:not(:disabled) {
            background: #f3f4f6;
            border-color: #9ca3af;
            transform: none;
            box-shadow: none;
        }

        .transcript-preview {
            background: white;
            border: 2px solid #e5e7eb;
            border-radius: 8px;
            padding: 15px;
            flex: 1;
            overflow-y: auto;
            margin-bottom: 15px;
            font-size: 13px;
            line-height: 1.6;
            color: #4b5563;
        }

        .transcript-preview.empty {
            color: #9ca3af;
            text-align: center;
            padding: 40px 20px;
        }

        .copy-feedback {
            background: #10b981;
            color: white;
            padding: 8px 16px;
            border-radius: 6px;
            font-size: 12px;
            text-align: center;
            margin-top: 10px;
            opacity: 0;
            transition: opacity 0.3s;
        }

        .copy-feedback.show {
            opacity: 1;
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .container {
                flex-direction: column;
            }

            .left-pane {
                border-right: none;
                border-bottom: 2px solid #e5e7eb;
            }

            .right-pane {
                max-height: 400px;
            }
        }
    </style>
</head>
<body>
    <div class="app-wrapper">
        <!-- Header with Session Info -->
        <div class="header">
            <div class="header-top">
                <div>
                    <h1>Streaming Automatic Speech Recognition</h1>
                    <p class="subtitle">Real-time speech recognition <span style="color: #9ca3af; font-size: 11px;">v2.3.0</span></p>
                </div>
                <div class="session-info">
                    <span>Session:</span>
                    <span class="session-id" id="sessionId">...</span>
                    <button id="shareBtn">ðŸ“‹ Share</button>
                </div>
            </div>
        </div>

        <!-- Split Pane Container -->
        <div class="container">
            <!-- Left Pane: Transcription -->
            <div class="left-pane">
                <div class="settings">
                    <div class="setting-group">
                        <label>Whisper Model</label>
                        <div style="padding: 10px; background: #f3f4f6; border-radius: 6px; color: #6b7280;">
                            faster-whisper-small.en (English only - Fast)
                        </div>
                    </div>
                    <div class="setting-group">
                        <label for="languageInput">Language Code</label>
                        <input type="text" id="languageInput" value="en" placeholder="en">
                    </div>
                </div>

                <div id="status" class="status disconnected">
                    <span class="indicator red"></span>
                    <span id="statusText">Disconnected</span>
                </div>

                <div class="controls">
                    <button id="startBtn">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"/>
                            <path d="M12 6v12"/>
                        </svg>
                        Start Recording
                    </button>
                    <button id="stopBtn" disabled>
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <rect x="6" y="6" width="12" height="12" rx="2"/>
                        </svg>
                        Stop Recording
                    </button>
                </div>

                <div class="transcript-box" id="transcriptBox">
                    <div style="color: #9ca3af; text-align: center; padding: 40px 20px;">
                        Click "Start Recording" to begin transcription
                    </div>
                </div>

                <div class="footer">
                    rewardie.com
                </div>
            </div>

            <!-- Right Pane: AI Assistant -->
            <div class="right-pane">
                <div class="panel-title">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"/>
                    </svg>
                    AI Assistant
                </div>

                <div class="action-buttons">
                    <button class="action-btn" id="copyTranscriptBtn">
                        ðŸ“‹ Copy All
                    </button>
                    <button class="action-btn" id="downloadTranscriptBtn">
                        ðŸ’¾ Download
                    </button>
                </div>

                <div class="transcript-preview empty" id="transcriptPreview">
                    <p>Transcript will appear here...</p>
                    <p style="margin-top: 10px; font-size: 12px;">You can copy or download the full transcript to use with Claude or other AI tools.</p>
                </div>

                <div class="copy-feedback" id="copyFeedback">
                    âœ“ Copied to clipboard!
                </div>
            </div>
        </div>
    </div>

    <script>
        // ============================================================
        // SESSION MANAGEMENT
        // ============================================================
        let sessionId = null;
        let fullTranscript = [];  // Array of {text, isFinal, timestamp}
        let seenFinalTexts = new Set();  // Track unique final transcripts
        let accumulatedText = '';  // Accumulated complete transcript
        let lastPartialText = '';  // Track last partial to detect new text

        function generateSessionId() {
            // Generate a short, readable session ID (8 chars)
            return Math.random().toString(36).substring(2, 10);
        }

        function getOrCreateSession() {
            const urlParams = new URLSearchParams(window.location.search);
            const sessionParam = urlParams.get('session');

            if (sessionParam) {
                // Join existing session
                sessionId = sessionParam;
                console.log('Joining session:', sessionId);
            } else {
                // Create new session
                sessionId = generateSessionId();
                console.log('Created new session:', sessionId);

                // Update URL without reload
                const newUrl = `${window.location.pathname}?session=${sessionId}`;
                window.history.replaceState({}, '', newUrl);
            }

            // Display session ID
            document.getElementById('sessionId').textContent = sessionId;
        }

        // Initialize session on page load
        getOrCreateSession();

        // ============================================================
        // UI ELEMENTS
        // ============================================================
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isRecording = false;

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const statusText = document.getElementById('statusText');
        const transcriptBox = document.getElementById('transcriptBox');
        const transcriptPreview = document.getElementById('transcriptPreview');
        const languageInput = document.getElementById('languageInput');
        const shareBtn = document.getElementById('shareBtn');
        const copyTranscriptBtn = document.getElementById('copyTranscriptBtn');
        const downloadTranscriptBtn = document.getElementById('downloadTranscriptBtn');
        const copyFeedback = document.getElementById('copyFeedback');

        function setStatus(state, message) {
            statusDiv.className = `status ${state}`;
            const indicator = statusDiv.querySelector('.indicator');
            indicator.className = 'indicator';

            if (state === 'connected' || state === 'recording') {
                indicator.classList.add('green');
            } else if (state === 'connecting') {
                indicator.classList.add('yellow');
            } else {
                indicator.classList.add('red');
            }

            statusText.textContent = message;
        }

        let lastDisplayedText = '';  // Track last displayed text to avoid duplicates

        function updateTranscriptPreview() {
            // Show accumulated text + current partial
            let previewText = accumulatedText;

            if (lastPartialText && lastPartialText !== accumulatedText) {
                previewText += (previewText ? ' ' : '') + lastPartialText;
            }

            if (previewText.trim()) {
                transcriptPreview.classList.remove('empty');
                transcriptPreview.textContent = previewText;
            } else {
                transcriptPreview.classList.add('empty');
                transcriptPreview.innerHTML = '<p>Transcript will appear here...</p><p style="margin-top: 10px; font-size: 12px;">You can copy or download the full transcript to use with Claude or other AI tools.</p>';
            }

            // Auto-scroll preview
            transcriptPreview.scrollTop = transcriptPreview.scrollHeight;
        }

        function addTranscript(text, isFinal = false) {
            // Normalize text for comparison (trim whitespace)
            const normalizedText = text.trim();

            // Accumulate text to prevent loss from sliding window
            if (isFinal) {
                // Final segment - save to accumulated
                if (seenFinalTexts.has(normalizedText)) {
                    console.log('Skipping duplicate final:', normalizedText.substring(0, 50) + '...');
                    return;
                }
                seenFinalTexts.add(normalizedText);
                accumulatedText += (accumulatedText ? ' ' : '') + normalizedText;
                lastPartialText = '';  // Reset partial tracking
            } else {
                // Partial segment - check if window slid
                if (lastPartialText && !normalizedText.includes(lastPartialText.substring(0, 50))) {
                    // Window slid! Save the old partial before it's lost
                    console.log('Window slid - saving previous partial');
                    accumulatedText += (accumulatedText ? ' ' : '') + lastPartialText;
                }
                lastPartialText = normalizedText;
            }

            const entry = document.createElement('div');
            entry.className = `transcript-entry ${isFinal ? 'final' : 'partial'}`;

            const label = document.createElement('div');
            label.className = 'transcript-label';
            label.textContent = isFinal ? 'Final' : 'Partial';

            const textDiv = document.createElement('div');
            textDiv.className = 'transcript-text';
            textDiv.textContent = text;

            entry.appendChild(label);
            entry.appendChild(textDiv);

            // Remove "Click Start" message if present
            if (transcriptBox.children.length === 1 &&
                transcriptBox.children[0].style.color === 'rgb(156, 163, 175)') {
                transcriptBox.innerHTML = '';
            }

            // Replace last partial or add new
            if (!isFinal && transcriptBox.lastChild &&
                transcriptBox.lastChild.classList.contains('partial')) {
                transcriptBox.replaceChild(entry, transcriptBox.lastChild);
            } else {
                transcriptBox.appendChild(entry);
            }

            // Track in fullTranscript array for export
            // WhisperLive sends CUMULATIVE finals, so replace (don't append)
            if (isFinal) {
                seenFinalTexts.add(normalizedText);

                // Replace fullTranscript with just the latest cumulative text
                fullTranscript = [{
                    text: text,
                    isFinal: true,
                    timestamp: new Date().toISOString()
                }];
            }

            // Update preview for both finals and partials
            updateTranscriptPreview();

            // Auto-scroll
            transcriptBox.scrollTop = transcriptBox.scrollHeight;
        }

        async function startRecording() {
            try {
                // Reset all tracking for new session
                lastDisplayedText = '';
                seenFinalTexts.clear();
                fullTranscript = [];
                accumulatedText = '';
                lastPartialText = '';

                setStatus('connecting', 'Connecting to server...');

                // Build WebSocket URL (wss:// on same host)
                const wsUrl = `wss://${window.location.host}/ws`;

                ws = new WebSocket(wsUrl);

                ws.onopen = async () => {
                    console.log('WebSocket connected');

                    // Send WhisperLive config message
                    const config = {
                        uid: 'browser-' + Date.now(),
                        task: 'transcribe',
                        language: languageInput.value,
                        model: 'Systran/faster-whisper-small.en',  // Fixed to small.en (only model that fits in T4 GPU)
                        use_vad: true  // Enable VAD to detect speech boundaries
                    };
                    console.log('Sending config:', config);
                    ws.send(JSON.stringify(config));

                    // Start audio capture with AudioContext
                    // WhisperLive expects raw Float32 PCM @ 16kHz, NOT WebM/Opus!
                    mediaStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            channelCount: 1,
                            sampleRate: 16000,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });

                    audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });
                    const source = audioContext.createMediaStreamSource(mediaStream);

                    // Create ScriptProcessor for raw audio (Float32)
                    processor = audioContext.createScriptProcessor(4096, 1, 1);

                    processor.onaudioprocess = (e) => {
                        if (!isRecording || ws.readyState !== WebSocket.OPEN) return;

                        // Send Float32Array directly - WhisperLive expects Float32!
                        const audioData = e.inputBuffer.getChannelData(0);
                        ws.send(audioData.buffer);
                    };

                    source.connect(processor);
                    processor.connect(audioContext.destination);

                    isRecording = true;
                    setStatus('recording', 'Recording... Speak now');
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                };

                ws.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);

                        // DEBUG: Log what we receive
                        console.log('WhisperLive message:', data);

                        // WhisperLive sends segments array
                        if (data.segments && data.segments.length > 0) {
                            // Concatenate all segment texts
                            const fullText = data.segments.map(s => s.text || '').join('');

                            // Check if last segment is final
                            const lastSegment = data.segments[data.segments.length - 1];
                            const isFinal = lastSegment.completed === true;

                            console.log('Segment:', {fullText: fullText.substring(0, 50), isFinal, completed: lastSegment.completed});

                            if (fullText.trim()) {
                                addTranscript(fullText, isFinal);
                            }
                        } else if (data.message === 'SERVER_READY') {
                            console.log('WhisperLive ready');
                        } else if (data.type === 'error') {
                            console.error('Server error:', data.message);
                            setStatus('disconnected', `Error: ${data.message}`);
                        }
                    } catch (e) {
                        console.error('Failed to parse message:', e);
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    setStatus('disconnected', 'Connection error');
                    stopRecording();
                };

                ws.onclose = (event) => {
                    console.log('WebSocket closed. Code:', event.code, 'Reason:', event.reason);
                    if (isRecording) {
                        setStatus('disconnected', `Connection closed (${event.code})`);
                        stopRecording();
                    }
                };

            } catch (error) {
                console.error('Failed to start recording:', error);
                setStatus('disconnected', `Error: ${error.message}`);
                stopRecording();
            }
        }

        function stopRecording() {
            isRecording = false;

            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.close();
            }

            ws = null;

            setStatus('disconnected', 'Disconnected');
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }

        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);

        // ============================================================
        // AI PANEL ACTIONS
        // ============================================================

        // Share button - copy session URL to clipboard
        shareBtn.addEventListener('click', async () => {
            const shareUrl = `${window.location.origin}${window.location.pathname}?session=${sessionId}`;

            try {
                await navigator.clipboard.writeText(shareUrl);
                const originalText = shareBtn.textContent;
                shareBtn.textContent = 'âœ“ Copied!';
                shareBtn.style.background = '#10b981';

                setTimeout(() => {
                    shareBtn.textContent = originalText;
                    shareBtn.style.background = '';
                }, 2000);
            } catch (err) {
                console.error('Failed to copy:', err);
                alert('Share URL: ' + shareUrl);
            }
        });

        // Copy transcript button
        copyTranscriptBtn.addEventListener('click', async () => {
            // Use accumulated text + current partial
            let fullText = accumulatedText;

            if (lastPartialText && lastPartialText !== accumulatedText) {
                fullText += (fullText ? ' ' : '') + lastPartialText;
            }

            if (!fullText.trim()) {
                alert('No transcript available yet. Start recording first!');
                return;
            }

            try {
                await navigator.clipboard.writeText(fullText);

                // Show feedback
                copyFeedback.classList.add('show');
                setTimeout(() => {
                    copyFeedback.classList.remove('show');
                }, 2000);
            } catch (err) {
                console.error('Failed to copy:', err);
                alert('Failed to copy to clipboard');
            }
        });

        // Download transcript button
        downloadTranscriptBtn.addEventListener('click', () => {
            const fullText = fullTranscript
                .filter(item => item.isFinal)
                .map(item => item.text)
                .join('\n\n');

            if (!fullText.trim()) {
                alert('No transcript available yet. Start recording first!');
                return;
            }

            // Create download
            const blob = new Blob([fullText], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `transcript-${sessionId}-${new Date().toISOString().split('T')[0]}.txt`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        });
    </script>
</body>
</html>
